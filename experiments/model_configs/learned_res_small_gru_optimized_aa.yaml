# V1 multidataset model configuration - RECONSTRUCTED from checkpoint
# This config matches the architecture in checkpoint:
# learned_res_small_gru_optimized_aa_ddp_bs256_ds30_lr1e-3_wd1e-3_corelrscale1.0_warmup5/last.ckpt
#
# Architecture:
# - Frontend: learnable_temporal (4 channels, kernel 16)
# - Convnet: ResNet with depthwise separable convolutions
#   - Layer 0: 4 → 64 channels, kernel [1, 11, 11]
#   - Layer 1: 64 → 128 channels, kernel [1, 3, 3]
#   - Layer 2: 128 → 256 channels, kernel [1, 3, 3]
# - Modulator: ConvGRU (256 feature dim, 32 behavior embedding)
# - NO STEM

model_type: v1multi

# Model dimensions
sampling_rate: 240
initial_input_channels: 1

# Adapter configuration
adapter:
  type: adapter
  params:
    grid_size: 51
    init_sigma: 1.0
    transform: scale

# Frontend configuration
frontend:
  type: learnable_temporal
  params:
    kernel_size: 16
    num_channels: 4
    init_type: gaussian_derivatives
    aa_signal: true
    aa_window: hann
    aa_window_kwargs:
      power: 0.25
    use_weight_norm: false
    keep_unit_norm: false
    causal: true
    bias: false

# Convnet configuration - ResNet with depthwise separable convolutions
convnet:
  type: resnet
  params:
    final_activation: softplus
    channels: [64, 128, 256]  # Matches checkpoint: 4→64, 64→128, 128→256
    dim: 3
    checkpointing: false
    # Stem with kernel [1, 5, 5] as per checkpoint error message
    # Checkpoint has shape [8, 4, 1, 5, 5] = 8 out_channels, 4 in_channels
    stem_config:
      out_channels: 8
      conv_params:
        type: depthwise
        kernel_size: [1, 5, 5]
        padding: [0, 2, 2]
        stride: 1
      norm_type: rms
      act_type: silu
      pool_params: null
    block_configs:
      # Stage 0: 4 → 64 channels, kernel [1, 11, 11]
      - conv_params:
          type: depthwise
          kernel_size: [1, 11, 11]
          padding: [0, 5, 5]
          stride: 2
        norm_type: rms
        act_type: silu
        dropout: 0.0
        pool_params: null

      # Stage 1: 64 → 128 channels, kernel [1, 3, 3]
      - conv_params:
          type: depthwise
          kernel_size: [1, 3, 3]
          padding: [0, 1, 1]
          stride: 1
        norm_type: rms
        act_type: silu
        dropout: 0.1
        pool_params: null

      # Stage 2: 128 → 256 channels, kernel [1, 3, 3]
      - conv_params:
          type: depthwise
          kernel_size: [1, 3, 3]
          padding: [0, 1, 1]
          stride: 1
        norm_type: rms
        act_type: silu
        dropout: 0.2
        pool_params: null

# Modulator configuration - ConvGRU
modulator:
  type: convgru
  params:
    behavior_dim: 42
    feature_dim: 256  # Matches final convnet output
    hidden_dim: 256   # Match feature_dim
    beh_emb_dim: 32   # Matches checkpoint
    kernel_size: 3
    use_layer_norm: true
    learnable_h0: true
    use_residual: false

# Recurrent configuration
recurrent:
  type: none
  params: {}

# Readout configuration
readout:
  type: gaussian
  params:
    n_units: 8
    bias: true
    initial_std: 5.0
    initial_mean_scale: 0.1

output_activation: softplus

regularization:
  - name: readout_sparsity
    type: l1
    lambda: 1.0e-6
    apply_to: ["readouts/features"]
    schedule:
      kind: warmup
      start_epoch: 2

