# V1 multidataset model configuration with eye position modulation
# This model has shared components (frontend, X3D, modulator)
# and experiment specific componenets (adapter, readout)
# the MLP behavior modulator is applied to the output of the convnet through a film layer
model_type: v1multi

# Model dimensions
sampling_rate: 240
initial_input_channels: 1 # number of channels in the input data

# Frontend configuration
adapter:
  type: adapter
  params: {grid_size: 51, init_sigma: 2.5, transform: scale}

frontend:
  type: learnable_temporal
  params: {kernel_size: 16, num_channels: 6, init_type: gaussian_derivatives,
          causal: true, bias: false}

# Convnet configuration
convnet:
  type: x3d
  params:
    dim: 3
    channels: [64, 128, 256]  # Simple progression for testing
    depth: [2, 2, 2]         # 2 blocks per stage
    t_kernel: 5              # Temporal kernel size
    s_kernel: 3              # Spatial kernel size
    exp_ratio: 4             # Expansion ratio in X3DUnit
    stride_stages: [1, 2, 2] # Temporal stride per stage
    spatial_stride_stages: [1, 2, 2]  # Spatial stride per stage
    norm_type: grn           # Group RMS normalization
    act_type: silu           # SiLU activation
    dropout: 0.1             # Dropout for regularization
    stochastic_depth: 0.1    # Stochastic depth for regularization
    checkpointing: true     # Memory checkpointing
    attention: se


# Modulator configuration
modulator:
  type: none
  params: {}

# # Recurrent configuration
# recurrent:
#   type: convgru
#   params:
#     hidden_dim: 128
#     kernel_size: 3

# Recurrent configuration
recurrent:
  type: none
  params: {}

# Readout configuration
readout:
  type: gaussianei
  params:
    n_units: 8
    bias: true
    initial_std_ex: 3.0
    initial_std_inh: 9.0
    weight_constraint_fn: relu

output_activation: softplus