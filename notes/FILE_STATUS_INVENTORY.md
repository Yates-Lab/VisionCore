# VisionCore Training Files - Status Inventory

## Legend

- âœ… **ACTIVE** - Currently used, keep as-is
- ğŸ”´ **DUPLICATE** - Remove immediately
- ğŸŸ¡ **DEPRECATED** - Move to deprecated folder
- ğŸŸ¢ **GOOD** - Well-organized, no changes needed
- âš ï¸ **REVIEW** - Needs manual review before action

---

## Training Scripts

### Active Training System

| File | Status | Lines | Action |
|------|--------|-------|--------|
| `training/train_ddp_multidataset.py` | âœ… ACTIVE | 1019 | Keep (canonical) |
| `training/regularizers.py` | âœ… ACTIVE | ~200 | Keep |

### Duplicate Training Scripts

| File | Status | Lines | Action |
|------|--------|-------|--------|
| `jake/multidataset_ddp/train_ddp_multidataset.py` | ğŸ”´ DUPLICATE | 1048 | **DELETE** |

**Difference:** 29 lines (likely minor edits or whitespace)

---

## Shell Scripts

### Active Shell Scripts (experiments/)

| File | Status | Purpose | Action |
|------|--------|---------|--------|
| `experiments/run_all_models.sh` | âœ… ACTIVE | Main training runner | Update path |
| `experiments/run_all_models_backimage.sh` | âœ… ACTIVE | Backimage experiments | Update path |
| `experiments/run_all_models_cones.sh` | âœ… ACTIVE | Cone experiments | Update path |
| `experiments/run_all_models_gaborium.sh` | âœ… ACTIVE | Gaborium experiments | Update path |
| `experiments/run_all_models_pretraining.sh` | âœ… ACTIVE | Pretraining experiments | Update path |

**Update:** Change `python train_ddp_multidataset.py` â†’ `python training/train_ddp_multidataset.py`

### Duplicate Shell Scripts (jake/multidataset_ddp/)

| File | Status | Action |
|------|--------|--------|
| `jake/multidataset_ddp/run_all_models.sh` | ğŸ”´ DUPLICATE | **DELETE** |
| `jake/multidataset_ddp/run_all_models_backimage.sh` | ğŸ”´ DUPLICATE | **DELETE** |
| `jake/multidataset_ddp/run_all_models_cones.sh` | ğŸ”´ DUPLICATE | **DELETE** |
| `jake/multidataset_ddp/run_all_models_gaborium.sh` | ğŸ”´ DUPLICATE | **DELETE** |
| `jake/multidataset_ddp/run_all_models_pretraining.sh` | âš ï¸ REVIEW | Check if unique |

---

## Lightning Modules

### Deprecated Lightning Modules (models/lightning/)

| File | Status | Lines | Used By | Action |
|------|--------|-------|---------|--------|
| `models/lightning/__init__.py` | ğŸŸ¡ DEPRECATED | 8 | Checkpoint loading | Update with deprecation warning |
| `models/lightning/core.py` | ğŸŸ¡ DEPRECATED | 367 | Old checkpoints only | Move to `models/lightning_deprecated/` |
| `models/lightning/multidataset.py` | ğŸŸ¡ DEPRECATED | 428 | Old checkpoints only | Move to `models/lightning_deprecated/` |

**Evidence of deprecation:**
```bash
# No active imports in training scripts
$ grep -r "from models.lightning import" training/
# (no results)

# Only used in checkpoint loading
$ grep -r "PLCoreVisionModel" .
models/checkpoint.py:    from .lightning import PLCoreVisionModel
models/model_manager.py: from .lightning import PLCoreVisionModel
```

### Active Lightning Modules (inline in train_ddp_multidataset.py)

| Component | Lines | Status | Action |
|-----------|-------|--------|--------|
| `MultiDatasetModel` | 493-903 | âœ… ACTIVE | Keep (or extract to `training/lightning/`) |
| `MultiDatasetDM` | 348-488 | âœ… ACTIVE | Keep (or extract to `training/lightning/`) |

---

## Supporting Components (inline in train_ddp_multidataset.py)

| Component | Lines | Status | Action |
|-----------|-------|--------|--------|
| `LinearWarmupCosineAnnealingLR` | 34-51 | âœ… ACTIVE | Keep (or extract to `training/schedulers.py`) |
| `Heartbeat` | 75-94 | ğŸŸ¡ COMMENTED | Remove (lines 130-154 are commented version) |
| `EpochHeartbeat` | 96-127 | âœ… ACTIVE | Keep (or extract to `training/callbacks.py`) |
| `CurriculumCallback` | 157-167 | âœ… ACTIVE | Keep (or extract to `training/callbacks.py`) |
| `ContrastWeightedSampler` | 198-343 | âœ… ACTIVE | Keep (or extract to `training/samplers.py`) |
| `cast_stim` | 172-174 | âœ… ACTIVE | Keep (or extract to `training/utils.py`) |
| `Float32View` | 176-186 | âœ… ACTIVE | Keep (or extract to `training/datasets.py`) |
| `group_collate` | 188-192 | âœ… ACTIVE | Keep (or extract to `training/utils.py`) |

---

## Commented/Dead Code

| Location | Lines | Status | Action |
|----------|-------|--------|--------|
| `train_ddp_multidataset.py` | 130-154 | ğŸ”´ DEAD CODE | **DELETE** (commented `PrintTimings`) |
| `train_ddp_multidataset.py` | 508 | ğŸ”´ DEAD CODE | **DELETE** (commented torch.compile) |
| `train_ddp_multidataset.py` | 678 | ğŸ”´ DEAD CODE | **DELETE** (commented autocast) |

---

## Model Configs

### Active Configs (configs/)

| File | Status | Action |
|------|--------|--------|
| `configs/learned_res_small.yaml` | âœ… ACTIVE | Keep |
| `configs/learned_res_small_gru.yaml` | âœ… ACTIVE | Keep |
| `configs/learned_res_small_pc.yaml` | âœ… ACTIVE | Keep |
| `configs/modulator_only_convgru.yaml` | âœ… ACTIVE | Keep |
| ... (many more) | âœ… ACTIVE | Keep |

**Note:** All configs in `configs/` appear to be actively used.

---

## Other Files in jake/multidataset_ddp/

| File | Status | Action |
|------|--------|--------|
| `jake/multidataset_ddp/gratings_cross_model_analysis_120.py` | âš ï¸ REVIEW | Check if unique analysis |
| `jake/multidataset_ddp/eval_stack_multidataset.py` | âš ï¸ REVIEW | Check if unique eval code |
| `jake/multidataset_ddp/eval_stack_utils.py` | âš ï¸ REVIEW | Check if unique utilities |

**Recommendation:** Review these files to see if they contain unique code or are duplicates.

---

## Summary Statistics

### Files to Delete (Phase 1)
- 1 duplicate training script
- 4-5 duplicate shell scripts
- 3 sections of commented code

**Total:** ~6 files + 3 code sections

### Files to Move (Phase 2)
- 2 deprecated Lightning modules
- 1 `__init__.py` to update

**Total:** 3 files

### Files to Extract (Phase 3 - Optional)
- 2 Lightning modules (MultiDatasetModel, MultiDatasetDM)
- 1 sampler (ContrastWeightedSampler)
- 3 callbacks (Heartbeat, EpochHeartbeat, CurriculumCallback)
- 1 scheduler (LinearWarmupCosineAnnealingLR)
- 3 utilities (cast_stim, Float32View, group_collate)

**Total:** 10 components â†’ 5-6 new files

---

## Dependency Graph

```
experiments/*.sh
    â†“
training/train_ddp_multidataset.py
    â”œâ”€â”€ MultiDatasetDM
    â”‚   â”œâ”€â”€ Float32View
    â”‚   â”œâ”€â”€ ContrastWeightedSampler
    â”‚   â””â”€â”€ group_collate
    â”œâ”€â”€ MultiDatasetModel
    â”‚   â”œâ”€â”€ training/regularizers.py
    â”‚   â””â”€â”€ models/losses.py
    â”œâ”€â”€ EpochHeartbeat
    â”œâ”€â”€ CurriculumCallback
    â””â”€â”€ LinearWarmupCosineAnnealingLR

models/checkpoint.py
    â””â”€â”€ models/lightning_deprecated/
        â”œâ”€â”€ PLCoreVisionModel
        â””â”€â”€ MultiDatasetPLCore
```

---

## Risk Assessment

### Low Risk (Safe to do now)
- âœ… Delete duplicate `train_ddp_multidataset.py`
- âœ… Delete duplicate shell scripts
- âœ… Update shell script paths
- âœ… Remove commented code

**Estimated time:** 30 minutes  
**Risk level:** Very Low  
**Rollback:** `git checkout -- .`

### Medium Risk (Test carefully)
- âš ï¸ Move Lightning modules to deprecated
- âš ï¸ Update checkpoint loading
- âš ï¸ Add deprecation warnings

**Estimated time:** 2-4 hours  
**Risk level:** Medium  
**Rollback:** `git checkout -- models/`

### High Risk (Plan carefully)
- ğŸ”´ Extract components to separate modules
- ğŸ”´ Refactor training script
- ğŸ”´ Update all imports

**Estimated time:** 1-2 days  
**Risk level:** High  
**Rollback:** Full git reset

---

## Verification Commands

### Check for duplicates
```bash
# Find duplicate training scripts
find . -name "train_ddp_multidataset.py" -type f

# Find duplicate shell scripts
find . -name "run_all_models*.sh" -type f
```

### Check for references
```bash
# Check what imports old Lightning modules
grep -r "from models.lightning import" . --exclude-dir=.git

# Check what uses PLCoreVisionModel
grep -r "PLCoreVisionModel" . --exclude-dir=.git

# Check what uses MultiDatasetPLCore
grep -r "MultiDatasetPLCore" . --exclude-dir=.git
```

### Check for commented code
```bash
# Find commented class definitions
grep -n "^# class" training/train_ddp_multidataset.py

# Find commented torch.compile
grep -n "# self.model = torch.compile" training/train_ddp_multidataset.py
```

---

## Cleanup Checklist

### Phase 1: Immediate Cleanup
- [ ] Run `bash cleanup_duplicates.sh --dry-run`
- [ ] Review output
- [ ] Run `bash cleanup_duplicates.sh`
- [ ] Test: `bash experiments/run_all_models.sh` (with small config)
- [ ] Remove commented code (lines 130-154, 508, 678)
- [ ] Commit: `git commit -m "Phase 1: Remove duplicates and dead code"`

### Phase 2: Deprecation
- [ ] Create `models/lightning_deprecated/`
- [ ] Move `core.py` and `multidataset.py`
- [ ] Update `models/lightning/__init__.py` with deprecation warnings
- [ ] Update `models/checkpoint.py` for backward compatibility
- [ ] Test loading old checkpoint (if available)
- [ ] Commit: `git commit -m "Phase 2: Deprecate old Lightning modules"`

### Phase 3: Extraction (Optional)
- [ ] Create `training/lightning/`
- [ ] Extract `MultiDatasetModel` â†’ `training/lightning/multidataset_model.py`
- [ ] Extract `MultiDatasetDM` â†’ `training/lightning/multidataset_dm.py`
- [ ] Extract samplers â†’ `training/samplers.py`
- [ ] Extract callbacks â†’ `training/callbacks.py`
- [ ] Extract schedulers â†’ `training/schedulers.py`
- [ ] Update `training/train_ddp_multidataset.py` to import from new locations
- [ ] Test full training pipeline
- [ ] Commit: `git commit -m "Phase 3: Extract components to modules"`

---

## Final State (After All Phases)

```
training/
â”œâ”€â”€ train_ddp_multidataset.py      (~200 lines - CLI only)
â”œâ”€â”€ regularizers.py                (existing)
â”œâ”€â”€ lightning/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ multidataset_model.py      (MultiDatasetModel)
â”‚   â””â”€â”€ multidataset_dm.py         (MultiDatasetDM + utilities)
â”œâ”€â”€ samplers.py                     (ContrastWeightedSampler)
â”œâ”€â”€ callbacks.py                    (Heartbeat, EpochHeartbeat, CurriculumCallback)
â””â”€â”€ schedulers.py                   (LinearWarmupCosineAnnealingLR)

models/
â”œâ”€â”€ lightning_deprecated/           (for old checkpoint loading)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ core.py                    (PLCoreVisionModel)
â”‚   â””â”€â”€ multidataset.py            (MultiDatasetPLCore)
â””â”€â”€ ...

experiments/
â”œâ”€â”€ run_all_models.sh              (updated paths)
â”œâ”€â”€ run_all_models_backimage.sh    (updated paths)
â”œâ”€â”€ run_all_models_cones.sh        (updated paths)
â”œâ”€â”€ run_all_models_gaborium.sh     (updated paths)
â””â”€â”€ run_all_models_pretraining.sh  (updated paths)

jake/multidataset_ddp/
â””â”€â”€ (cleaned up - only unique files remain)
```

---

## Questions Before Cleanup

1. **Are there any running experiments?**
   - âš ï¸ Wait for them to finish before cleanup

2. **Do we have old checkpoints to test?**
   - âœ… Yes â†’ Test Phase 2 carefully
   - âŒ No â†’ Can skip backward compatibility

3. **Is jake/multidataset_ddp/ a development sandbox?**
   - âœ… Yes â†’ Safe to clean up duplicates
   - âŒ No â†’ Review unique files first

4. **When should we do this?**
   - ğŸƒ Now â†’ Do Phase 1 (30 min)
   - ğŸ“… This week â†’ Do Phase 1-2 (4 hours)
   - ğŸ—“ï¸ This month â†’ Do Phase 1-3 (2 days)

